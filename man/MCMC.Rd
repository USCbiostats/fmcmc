% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/mcmc.r
\name{MCMC}
\alias{MCMC}
\alias{Metropolis-Hastings}
\title{Markov Chain Monte Carlo}
\usage{
MCMC(fun, ..., initial, nbatch, nchains = 1L, thin = 1L, scale = 1,
  burnin = 1000L, ub = .Machine$double.xmax,
  lb = -.Machine$double.xmax, useCpp = FALSE, cl = NULL,
  fixed = FALSE, multicore = FALSE,
  conv_checker = auto_convergence(), autostop = 500L)
}
\arguments{
\item{fun}{A function. Returns the log-likelihood}

\item{...}{Further arguments passed to \code{fun}.}

\item{initial}{A numeric vector or matrix with as many rows as chains with
initial values of the parameters for each chain (See details).}

\item{nbatch}{Integer scalar. Number of MCMC runs.}

\item{nchains}{Integer scalar. Number of chains to run (in parallel).}

\item{thin}{Integer scalar. Passed to \code{\link[coda:mcmc]{coda::mcmc}}.}

\item{scale}{Either a numeric vector of length \code{length(initial)} or a
scalar. Step size for the transition kernel (see details).}

\item{burnin}{Integer scalar. Number of burn-in samples. Passed to
\code{\link[coda:mcmc]{coda::mcmc}} as \code{init}.}

\item{ub}{Numeric vector of length \code{length(initial)}. Upper bounds}

\item{lb}{Numeric vector of length \code{length(initial)}. Lower bounds}

\item{useCpp}{Logical scalar. When \code{TRUE}, loops using a Rcpp implementation.}

\item{cl}{A cluster object passed to \code{\link[parallel:clusterApply]{clusterApply}}.}

\item{fixed}{Logical vector. If the kth position is \code{TRUE}, then that
value will be fixed.}

\item{multicore}{Logical. If \code{FALSE} then it will execute the chains in a serial
fashion.}

\item{conv_checker}{A function that receives an object of class \link[coda:mcmc.list]{coda::mcmc.list},
and returns a logical value with \code{TRUE} indicating convergence.}

\item{autostop}{Integer scalar. Frequency used to check for convergence.
By default the function uses \link{gelman_convergence} as criteria.}
}
\value{
An object of class \code{\link[coda:mcmc]{mcmc}} from the \CRANpkg{coda}
package. The \code{mcmc} object is a matrix with one column per parameter,
and \code{nbatch} rows. If \code{nchains > 1}, then it returns a \code{\link[coda:mcmc]{mcmc.list}}.
}
\description{
Metropolis-Hastings algorithm using a random walk kernel with reflecting boundaries.
}
\details{
This function implements MCMC using the Metropolis-Hastings ratio with
scaled standard normal propositions for each parameter. For each parameter
the transition function is

\deqn{
\theta' = \theta + scale*z
}

Where \eqn{z} has standard normal distribution. The MCMC follows a block
sampling scheme, i.e. proposed states are either accepted or rejected
altogether. If \code{length(initial) > 1} and \code{length(scale) == 1},
the value will be recycled so that \code{length(initial) == length(scale)}.

Lower and upper bounds are treated using reflecting boundaries, this is,
if the proposed \eqn{\theta'} is greater than the \code{ub}, then \eqn{\theta' - ub}
is substracted from \eqn{ub}. At the same time, if it is less than \code{lb}, then
\eqn{lb - \theta'} is added to \code{lb} iterating until \eqn{\theta} is within
\code{[lb, ub]}.

If \code{name(initial) == NULL}, then a names in the form of \code{par1, par2, ...}
will be assigned to the variables.

When \code{nchains > 1}, the function will run multiple chains. Furthermore,
if \code{cl} is not passed, \code{MCMC} will create a \code{PSOCK} cluster
using \code{\link[parallel:makePSOCKcluster]{makePSOCKcluster}} with
\code{\link[parallel:detectCores]{detectCores}}
clusters and try to run it using multiple cores. Internally, the function does
the following:

\preformatted{
  # Creating the cluster
  ncores <- parallel::detectCores()
  ncores <- ifelse(nchains < ncores, nchains, ncores)
  cl     <- parallel::makePSOCKcluster(ncores)
  
  # Loading the package and setting the seed using clusterRNGStream
  invisible(parallel::clusterEvalQ(cl, library(amcmc)))
  parallel::clusterSetRNGStream(cl, .Random.seed)
}

In such case, when running in parallel, objects that are
used within \code{fun} must be passed throught \code{...}, otherwise the cluster
will return with an error.

In the case of the initial parameter, when using multiple chains, \code{nchains > 1},
the user can specify multiple starting points (which is recommended). In such
case, if \code{initial} is a vector, the value is recycled (so all chains start from
the same point), otherwise, if \code{initial} is a matrix with as many rows as
chains, then each row of \code{initial} is use as a starting point for each of the
chains.
}
\section{Automatic stop}{


When \code{autostop} is greater than 0, the function will perform a convergence
check every \code{autostop} steps. By default, the convergence check is done
using the Gelman diagostic as implemented in \link[coda:gelman.diag]{coda::gelman.diag}, so it will
only be calculated when \code{nchains > 1L}.

The user may provide a different convergence criteria by passing a different
function via \code{conv_checker}. It's current default is \link{gelman_convergence}.
}

\examples{
# Univariate distributed data with multiple parameters ----------------------
# Parameters
set.seed(1231)
n <- 1e3
pars <- c(mean = 2.6, sd = 3)

# Generating data and writing the log likelihood function
D <- rnorm(n, pars[1], pars[2])
fun <- function(x) {
  x <- log(dnorm(D, x[1], x[2]))
  sum(x)
}

# Calling MCMC, but first, loading the coda R package for
# diagnostics
library(coda)
ans <- MCMC(fun, initial = c(mu=1, sigma=1), nbatch = 2e3, scale = .1,
   ub = 10, lb = 0)

# Ploting the output
oldpar <- par(no.readonly = TRUE)
par(mfrow = c(1,2))
boxplot(as.matrix(ans), 
        main = expression("Posterior distribution of"~mu~and~sigma),
        names =  expression(mu, sigma), horizontal = TRUE,
        col  = blues9[c(4,9)],
        sub = bquote(mu == .(pars[1])~", and"~sigma == .(pars[2]))
)
abline(v = pars, col  = blues9[c(4,9)], lwd = 2, lty = 2)

plot(apply(as.matrix(ans), 1, fun), type = "l",
     main = "LogLikelihood",
     ylab = expression(L("{"~mu,sigma~"}"~"|"~D)) 
)
par(oldpar)

\dontrun{
# In this example we estimate the parameter for a dataset with ----------------
# With 5,000 draws from a MVN() with parameters M and S.

# Loading the required packages
library(mvtnorm)
library(coda)

# Parameters and data simulation
S <- cbind(c(.8, .2), c(.2, 1))
M <- c(0, 1)

set.seed(123)
D <- rmvnorm(5e3, mean = M, sigma = S)

# Function to pass to MCMC
fun <- function(pars) {
  # Putting the parameters in a sensible way
  m <- pars[1:2]
  s <- cbind( c(pars[3], pars[4]), c(pars[4], pars[5]) )
  
  # Computing the unnormalized log likelihood
  sum(log(dmvnorm(D, m, s)))
}

# Calling MCMC
ans <- MCMC(
  fun,
  initial = c(mu0=5, mu1=5, s0=5, s01=0, s2=5), 
  lb      = c(-10, -10, .01, -5, .01),
  ub      = 5,
  nbatch  = 1e5,
  thin    = 20,
  scale   = .01,
  burnin  = 5e3,
  useCpp  = TRUE
)

# Checking out the outcomes
plot(ans)
summary(ans)

# Multiple chains -----------------------------------------------------------

# As we want to run -fun- in multiple cores, we have to
# pass -D- explicitly (unless using Fork Clusters)
# just like specifying that we are calling a function from the
# -mvtnorm- package.
  
fun <- function(pars, D) {
  # Putting the parameters in a sensible way
  m <- pars[1:2]
  s <- cbind( c(pars[3], pars[4]), c(pars[4], pars[5]) )
  
  # Computing the unnormalized log likelihood
  sum(log(mvtnorm::dmvnorm(D, m, s)))
}

# Two chains
ans <- MCMC(
  fun,
  initial = c(mu0=5, mu1=5, s0=5, s01=0, s2=5), 
  nchains = 2,
  lb      = c(-10, -10, .01, -5, .01),
  ub      = 5,
  nbatch  = 1e5,
  thin    = 20,
  scale   = .01,
  burnin  = 5e3,
  useCpp  = TRUE,
  D       = D
)

summary(ans)
}

}
